{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wine.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>14.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>2.45</td>\n",
       "      <td>14.6</td>\n",
       "      <td>96</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.52</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>14.06</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.61</td>\n",
       "      <td>17.6</td>\n",
       "      <td>121</td>\n",
       "      <td>2.60</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>14.83</td>\n",
       "      <td>1.64</td>\n",
       "      <td>2.17</td>\n",
       "      <td>14.0</td>\n",
       "      <td>97</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.98</td>\n",
       "      <td>5.20</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>13.86</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.27</td>\n",
       "      <td>16.0</td>\n",
       "      <td>98</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.22</td>\n",
       "      <td>1.01</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "5   1  14.20  1.76  2.45  15.2  112  3.27  3.39  0.34  1.97  6.75  1.05  2.85   \n",
       "6   1  14.39  1.87  2.45  14.6   96  2.50  2.52  0.30  1.98  5.25  1.02  3.58   \n",
       "7   1  14.06  2.15  2.61  17.6  121  2.60  2.51  0.31  1.25  5.05  1.06  3.58   \n",
       "8   1  14.83  1.64  2.17  14.0   97  2.80  2.98  0.29  1.98  5.20  1.08  2.85   \n",
       "9   1  13.86  1.35  2.27  16.0   98  2.98  3.15  0.22  1.85  7.22  1.01  3.55   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  \n",
       "5  1450  \n",
       "6  1290  \n",
       "7  1295  \n",
       "8  1045  \n",
       "9  1045  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2796a7a9bc8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(0, axis=1)\n",
    "y = df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
      "0  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
      "1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
      "2  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
      "3  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
      "4  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
      "\n",
      "     13  \n",
      "0  1065  \n",
      "1  1050  \n",
      "2  1185  \n",
      "3  1480  \n",
      "4   735  \n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "model1 = svm.SVC()\n",
    "classifiers.append(model1)\n",
    "model2 = tree.DecisionTreeClassifier()\n",
    "classifiers.append(model2)\n",
    "model3 = RandomForestClassifier()\n",
    "classifiers.append(model3)\n",
    "model4 = KN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) is 0.6481481481481481\n",
      "Confusion Matrix of SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) is [[18  1  0]\n",
      " [ 0 17  0]\n",
      " [ 0 18  0]]\n",
      "Accuracy of DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') is 0.9259259259259259\n",
      "Confusion Matrix of DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best') is [[19  0  0]\n",
      " [ 1 16  0]\n",
      " [ 0  3 15]]\n",
      "Accuracy of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) is 1.0\n",
      "Confusion Matrix of RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False) is [[19  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred= clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
